{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poet Poems Scraping from Ganjoor Website\n",
    "\n",
    "This Python script is designed to scrape poets' poems from the Ganjoor website. It provides a set of functions to extract poems, their excerpts, and related details from the website's pages, and save them into CSV files based on specified criteria.\n",
    "\n",
    "## Functionality\n",
    "\n",
    "The script comprises several functions:\n",
    "\n",
    "1. **`get_poem(url)`**: This function extracts a poem from a provided URL of a webpage containing the poem. It parses the HTML content, retrieves the verses, calculates the number of verses and words, and returns the poem text along with these details.\n",
    "\n",
    "2. **`get_book_urls(url, prefix=\"https://ganjoor.net\")`**: This function retrieves URLs of books from a given URL. It extracts the URLs from the webpage and appends them with a provided prefix, typically the Ganjoor website URL.\n",
    "\n",
    "3. **`get_part_urls(url, prefix=\"https://ganjoor.net\")`**: This function extracts URLs of each poem's full version from a webpage containing a collection of poem excerpts. It appends them with a given prefix to form complete URLs.\n",
    "\n",
    "4. **`get_poet(poet_links, directory=\"./result\", number_of_doc_words=700, print_details=False)`**: This main function takes a list of URLs of poet pages, extracts their poems, and saves them in CSV files according to specified criteria. It iterates over the poet links, retrieves the URLs of books written by each poet, then extracts the URLs of poem excerpts from each book. It further utilizes the `get_poem()` function to extract the poems, considering a maximum number of words per document. Finally, it saves the poems into CSV files and returns a list of dictionaries containing details about the processed documents.\n",
    "\n",
    "## Usage\n",
    "\n",
    "To use this script:\n",
    "- Provide a list of URLs of poet pages.\n",
    "- Specify the directory where the CSV files will be saved.\n",
    "- Optionally set the maximum number of words per document and whether to print details during processing.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "```python\n",
    "poet_links = [\"https://example.com/poet1\", \"https://example.com/poet2\"]\n",
    "details = get_poet(poet_links, directory=\"./poems\", number_of_doc_words=800, print_details=True)\n",
    "print(\"Details:\", details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:10:07.210659Z",
     "start_time": "2024-02-13T12:10:07.166217Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Description\n",
    "\n",
    "This function, `get_poem(url)`, retrieves a poem from a specified URL. It extracts the verses from the webpage and calculates the number of verses and words in the poem.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- `url` (str): The URL of the webpage containing the poem.\n",
    "\n",
    "### Returns\n",
    "\n",
    "A tuple with the following elements:\n",
    "\n",
    "1. **Poem Text** (str): The text of the poem.\n",
    "2. **Number of Verses** (int): The total number of verses in the poem.\n",
    "3. **Number of Words** (int): The total number of words in the poem.\n",
    "\n",
    "### Libraries Used\n",
    "\n",
    "- `requests`: Used for sending HTTP requests.\n",
    "- `BeautifulSoup` (from `bs4`): Used for parsing HTML content.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "poem_text, num_verses, num_words = get_poem(\"https://example.com/poem\")\n",
    "print(\"Poem Text:\", poem_text)\n",
    "print(\"Number of Verses:\", num_verses)\n",
    "print(\"Number of Words:\", num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:29:24.818022Z",
     "start_time": "2024-02-13T12:29:24.747111Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_poem(url):\n",
    "    \"\"\"\n",
    "    This function takes a URL of a webpage containing a poem, extracts the verses, and calculates the number of verses \n",
    "    and words in the poem.\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): The URL of the webpage containing the poem.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing the poem text, number of verses, and number of words in the poem.\n",
    "    \"\"\"\n",
    "    # Import necessary libraries\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    # Send a GET request to the provided URL\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Create a BeautifulSoup object to parse the HTML content of the webpage\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    # Find all <div> elements with class 'b' which typically contain the verses of the poem\n",
    "    verses = soup.findAll('div', attrs={'class': 'b'})\n",
    "    \n",
    "    # Extract the text of each verse and join them with newline characters to form the poem text\n",
    "    poem = \"\\n\".join([b.text for b in verses])\n",
    "    \n",
    "    # Calculate the number of verses in the poem\n",
    "    verse_num = len(verses)\n",
    "    \n",
    "    # Calculate the total number of words in the poem\n",
    "    word_num = sum([len(verse.text.split()) or 0 for verse in verses])\n",
    "    \n",
    "    # Return a tuple containing the poem text, number of verses, and number of words\n",
    "    return (poem, verse_num, word_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Description\n",
    "\n",
    "This function, `get_book_urls(url, prefix=\"https://ganjoor.net\")`, retrieves URLs of books from a specified URL. It extracts the URLs from the webpage and appends them with the provided prefix.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- `url` (str): The URL of the webpage containing the book URLs.\n",
    "- `prefix` (str, optional): The prefix to be appended to the extracted URLs. Defaults to `\"https://ganjoor.net\"`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "A list of URLs of books.\n",
    "\n",
    "### Libraries Used\n",
    "\n",
    "- `requests`: Used for sending HTTP requests.\n",
    "- `BeautifulSoup` (from `bs4`): Used for parsing HTML content.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "book_urls = get_book_urls(\"https://example.com/books\")\n",
    "print(\"Book URLs:\", book_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_urls(url,prefix = \"https://ganjoor.net\"):\n",
    "\tr = requests.get(url)\n",
    "\tsoup = BeautifulSoup(r.content)\n",
    "\tparts = soup.findAll('div',attrs={'class':'part-title-block'})\n",
    "\tparts=[f'{prefix}/{b.find(\"a\")[\"href\"]}' for b in parts]\n",
    "\treturn parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Description\n",
    "\n",
    "This function, `get_part_urls(url, prefix=\"https://ganjoor.net\")`, extracts URLs of each poem's full version from a webpage containing a collection of poem excerpts. It then appends them with a given prefix to form complete URLs.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- `url` (str): The URL of the webpage containing the poem excerpts.\n",
    "- `prefix` (str, optional): The prefix to be added to the extracted URLs. Default is `\"https://ganjoor.net\"`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "A list containing the complete URLs of each poem's full version.\n",
    "\n",
    "### Libraries Used\n",
    "\n",
    "- `requests`: Used for sending HTTP requests.\n",
    "- `BeautifulSoup` (from `bs4`): Used for parsing HTML content.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "part_urls = get_part_urls(\"https://example.com/poem-excerpts\")\n",
    "print(\"Part URLs:\", part_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_urls(url, prefix=\"https://ganjoor.net\"):\n",
    "    \"\"\"\n",
    "    This function takes a URL of a webpage containing a collection of poem excerpts and extracts the URLs of each \n",
    "    poem's full version. It then appends them with a given prefix to form complete URLs.\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): The URL of the webpage containing the poem excerpts.\n",
    "        prefix (str, optional): The prefix to be added to the extracted URLs. Default is \"https://ganjoor.net\".\n",
    "    \n",
    "    Returns:\n",
    "        list: A list containing the complete URLs of each poem's full version.\n",
    "    \"\"\"\n",
    "    # Import necessary libraries\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    # Send a GET request to the provided URL\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # Create a BeautifulSoup object to parse the HTML content of the webpage\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    \n",
    "    # Find all <p> elements with class 'poem-excerpt' which typically contain links to poem excerpts\n",
    "    parts = soup.findAll('p', attrs={'class': 'poem-excerpt'})\n",
    "    \n",
    "    # Extract the URLs from each <a> tag found within <p> elements and append them with the prefix\n",
    "    parts = [f'{prefix}/{b.find(\"a\")[\"href\"]}' for b in parts]\n",
    "    \n",
    "    # Return the list of complete URLs\n",
    "    return parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Description\n",
    "\n",
    "This function, `get_poet(poet_links, directory=\"./result\", number_of_doc_words=700, print_details=False)`, extracts poems from a list of URLs of poet pages and saves them in CSV files based on specified criteria.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- `poet_links` (list): A list of URLs of poet pages.\n",
    "- `directory` (str, optional): The directory where the CSV files will be saved. Default is `\"./result\"`.\n",
    "- `number_of_doc_words` (int, optional): The maximum number of words per document. Default is `700`.\n",
    "- `print_details` (bool, optional): Whether to print details during processing. Default is `False`.\n",
    "\n",
    "### Returns\n",
    "\n",
    "A list of dictionaries containing details about the processed documents.\n",
    "\n",
    "### Libraries Used\n",
    "\n",
    "- `os`: Used for operating system-related functions.\n",
    "- `csv`: Used for reading and writing CSV files.\n",
    "- `get_book_urls`: A function to retrieve URLs of books from a webpage.\n",
    "- `get_part_urls`: A function to retrieve URLs of poem excerpts from a webpage.\n",
    "- `get_poem`: A function to retrieve the text, number of verses, and number of words of a poem from a webpage.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "poet_links = [\"https://example.com/poet1\", \"https://example.com/poet2\"]\n",
    "details = get_poet(poet_links, directory=\"./poems\", number_of_doc_words=800, print_details=True)\n",
    "print(\"Details:\", details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def get_poet(poet_links, directory=\"./result\", number_of_doc_words=700, print_details=False):\n",
    "    \"\"\"\n",
    "    This function takes a list of URLs of poet pages, extracts their poems, and saves them in CSV files according to \n",
    "    specified criteria.\n",
    "    \n",
    "    Parameters:\n",
    "        poet_links (list): A list of URLs of poet pages.\n",
    "        directory (str, optional): The directory where the CSV files will be saved. Default is \"./result\".\n",
    "        number_of_doc_words (int, optional): The maximum number of words per document. Default is 700.\n",
    "        print_details (bool, optional): Whether to print details during processing. Default is False.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing details about the processed documents.\n",
    "    \"\"\"\n",
    "    # Import necessary libraries\n",
    "    import os\n",
    "    import csv\n",
    "    \n",
    "    # Define the author name based on the first poet link\n",
    "    a_name = poet_links[0][20:].split(\"/\")[0]\n",
    "    \n",
    "    # Define the file name for the CSV file\n",
    "    f_name = f\"{directory}/{a_name}.csv\"\n",
    "    \n",
    "    # Create the result directory if it doesn't exist\n",
    "    try:\n",
    "        os.mkdir(directory)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(f_name, 'w', newline='') as f_all:\n",
    "        # Create a CSV writer object\n",
    "        w = csv.DictWriter(f_all, ['author', 'b_name', 'p_name', 'text'])\n",
    "        # Write the header row\n",
    "        w.writeheader()\n",
    "\n",
    "        # Initialize variables for document word count and details\n",
    "        n_doc = 0\n",
    "        n_doc_words = 0\n",
    "        doc = \"\"\n",
    "        details = []\n",
    "        \n",
    "        # Iterate over each poet link\n",
    "        for poet_link in poet_links:\n",
    "            # Get the URLs of books written by the poet\n",
    "            book_urls = get_book_urls(poet_link)\n",
    "\n",
    "            # Iterate over each book URL\n",
    "            for b_url in book_urls:\n",
    "                n_doc_words = 0\n",
    "                doc = \"\"\n",
    "                \n",
    "                # Get the URLs of parts (poem excerpts) in the book\n",
    "                part_urls = get_part_urls(b_url)\n",
    "                \n",
    "                # Iterate over each part URL\n",
    "                for url in part_urls:\n",
    "                    # Get the poem text, number of verses, and number of words\n",
    "                    poem, verse_num, word_num = get_poem(url)\n",
    "                    \n",
    "                    # Append poem text to the document and update word count\n",
    "                    doc += f\"\\n{poem}\"\n",
    "                    n_doc_words += word_num\n",
    "                    \n",
    "                    # Check if document word count exceeds the threshold\n",
    "                    if n_doc_words > number_of_doc_words:\n",
    "                        # Optionally print details\n",
    "                        print_details and print(f\"{url} : {n_doc_words}\")\n",
    "                        \n",
    "                        # Write the document details to the CSV file\n",
    "                        w.writerow({\n",
    "                            \"author\": url[20:].split(\"/\")[0],\n",
    "                            \"b_name\": url[20:].split(\"/\")[1],\n",
    "                            \"p_name\": url[20:].split(\"/\")[2],\n",
    "                            \"text\": doc\n",
    "                        })\n",
    "                        \n",
    "                        # Append details to the list\n",
    "                        details.append({\n",
    "                            \"author\": url[20:].split(\"/\")[0],\n",
    "                            \"b_name\": url[20:].split(\"/\")[1],\n",
    "                            \"n_doc_words\": n_doc_words,\n",
    "                            \"n_doc\": n_doc\n",
    "                        })\n",
    "                        \n",
    "                        # Reset document word count and content\n",
    "                        n_doc_words = 0\n",
    "                        doc = \"\"\n",
    "                        n_doc += 1\n",
    "                        \n",
    "                        # Check if the maximum number of documents has been reached\n",
    "                        if n_doc > 30:\n",
    "                            return details\n",
    "        \n",
    "        return details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_poet([\"https://ganjoor.net/shahriar\"] , print_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "poets = [\n",
    "    # [\"https://ganjoor.net/bahar\"],\n",
    "    # [\"https://ganjoor.net/iqbal\"],\n",
    "    [\"https://ganjoor.net/attar/manteghotteyr\",\"https://ganjoor.net/attar/elahiname\",\"https://ganjoor.net/attar/asrarname\"]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ganjoor.net//attar/manteghotteyr/touhid/sh1 : 817\n",
      "https://ganjoor.net//attar/manteghotteyr/touhid/sh2 : 2569\n",
      "https://ganjoor.net//attar/manteghotteyr/naat/sh1 : 1731\n",
      "https://ganjoor.net//attar/manteghotteyr/taassob/sh3 : 818\n",
      "https://ganjoor.net//attar/manteghotteyr/taassob/sh8 : 895\n",
      "https://ganjoor.net//attar/manteghotteyr/aghazm/sh1 : 1467\n",
      "https://ganjoor.net//attar/manteghotteyr/porsesh/sh2 : 840\n",
      "https://ganjoor.net//attar/manteghotteyr/hodhod/sh2 : 5383\n",
      "https://ganjoor.net//attar/manteghotteyr/azm-rah/sh2 : 901\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh3 : 1265\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh8 : 848\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh12 : 725\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh16 : 971\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh21 : 775\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh24 : 793\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh28 : 815\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh33 : 913\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh38 : 917\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh42 : 784\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh47 : 733\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh50 : 758\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh55 : 869\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh60 : 808\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh64 : 829\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh66 : 731\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh72 : 874\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh75 : 916\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh80 : 707\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh86 : 838\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh90 : 785\n",
      "https://ganjoor.net//attar/manteghotteyr/ozr-morghan/sh94 : 822\n"
     ]
    }
   ],
   "source": [
    "for poet in poets :\n",
    "    get_poet(poet , print_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_poet([\"https://ganjoor.net/jami/divanj/fateha-shabab\",\"https://ganjoor.net/jami/divanj/khatema-hayat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
